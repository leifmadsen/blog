<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Asterisk, and other worldly endeavours</title>
    <link>http://blog.leifmadsen.com/</link>
    <description>Recent content on Asterisk, and other worldly endeavours</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Oct 2016 15:34:08 -0400</lastBuildDate>
    <atom:link href="http://blog.leifmadsen.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TripleO: Consuming Composable Roles</title>
      <link>http://blog.leifmadsen.com/blog/2016/10/03/tripleo-consuming-composable-roles/</link>
      <pubDate>Mon, 03 Oct 2016 15:34:08 -0400</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2016/10/03/tripleo-consuming-composable-roles/</guid>
      <description>

&lt;p&gt;So last week I started to look into learning the new &lt;a href=&#34;http://hardysteven.blogspot.ca/2016/08/tripleo-composable-services-101.html&#34;&gt;composable services and
roles&lt;/a&gt;
that was added to Newton. I previously learned a little bit about deploying
OpenStack clouds when I did training after joining Red Hat, but that was based
on Liberty, and a lot has changed in TripleO since that time.&lt;/p&gt;

&lt;p&gt;The first thing was learning what composable services and roles are, and
generally what they are intended to solve. I don&amp;rsquo;t want to get into that
here, so I&amp;rsquo;d encourage you to go read some links first and then come back here.
Additionally, it&amp;rsquo;s assumed you know what a TripleO is :)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blueprints.launchpad.net/tripleo/+spec/composable-services-within-roles&#34;&gt;TripleO Composable Services Within
Roles Blueprint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tripleo.org/developer/tht_walkthrough/tht_walkthrough.html&#34;&gt;TripleO Composable Services
Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gX5AKSqRCiU&#34;&gt;TripleO Deep Dive: TripleO Heat
Templates&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;m not really going to be showing anything too magical here. The primary use
case is getting bootstrapped so we can start playing with TripleO Heat
Templates (THT) and deploy using the &lt;code&gt;roles_data.yml&lt;/code&gt; file along with our own
template files.&lt;/p&gt;

&lt;h2 id=&#34;getting-a-working-environment&#34;&gt;Getting a working environment&lt;/h2&gt;

&lt;p&gt;I have access to a machine with a good amount of resources (12 cores, 24 with
HT, and 64GB of memory) so I&amp;rsquo;m doing everything here in a virtual environment.
Additionally, I&amp;rsquo;m using &lt;a href=&#34;https://github.com/openstack/tripleo-quickstart&#34;&gt;TripleO
Quickstart&lt;/a&gt; to get my
undercloud up and running along with instantiating the overcloud VMs (but not
provisioning them).&lt;/p&gt;

&lt;p&gt;First I created a new configuration file to define the environment I wanted to
build. I create a single controller and three compute nodes. I did this
primarily so I could test scaling up and down the compute nodes.&lt;/p&gt;

&lt;p&gt;The configuration file is exactly what is defined
&lt;code&gt;config/general_config/minimal.yml&lt;/code&gt; but I added more another 2 compute nodes to
the list. Here is the file as tested:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# We run tempest in this topology instead of ping test.
# We set introspection to true and use only the minimal amount of nodes
# for this job, but test all defaults otherwise.
step_introspect: true

# Define a single controller node and a single compute node.
overcloud_nodes:
  - name: control_0
    flavor: control

  - name: compute_0
    flavor: compute
  - name: compute_1
    flavor: compute
  - name: compute_2
    flavor: compute

# Tell tripleo how we want things done.
extra_args: &amp;gt;-
  --neutron-network-type vxlan
  --neutron-tunnel-types vxlan
  --ntp-server pool.ntp.org

network_isolation: true

# If `test_tempest` is `true`, run tempests tests, otherwise do not
# run them.
tempest_config: true
test_ping: false
run_tempest: true

# options below direct automatic doc generation by tripleo-collect-logs
artcl_gen_docs: true
artcl_create_docs_payload:
  included_deployment_scripts:
    - undercloud-install
    - undercloud-post-install
    - overcloud-deploy
    - overcloud-deploy-post
    - overcloud-validate
  included_static_docs:
    - env-setup-virt
  table_of_contents:
    - env-setup-virt
    - undercloud-install
    - undercloud-post-install
    - overcloud-deploy
    - overcloud-deploy-post
    - overcloud-validate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then I deployed my environment with &lt;strong&gt;oooq&lt;/strong&gt; using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./quickstart.sh \
  --working-dir ~/quickstart \
  --no-clone \
  --bootstrap \
  --teardown all \
  --tags all \
  --skip-tags overcloud-validate,overcloud-deploy \
  --config ./config/general_config/1-plus-3.yml \
  --release master \
  --playbook quickstart-extras.yml \
  127.0.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;quickstart-extras.yml&lt;/code&gt; will make sure our overcloud scripts are added to
the undercloud, and that some other nice things happen like making sure images
are pulled down and put onto the undercloud, along with a default
&lt;code&gt;network-environment.yml&lt;/code&gt; file being created.&lt;/p&gt;

&lt;p&gt;TripleO Quickstart (oooq) will then spin up our VMs and we can validate this
with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo su - stack
$ virsh list --all
 Id    Name                           State
----------------------------------------------------
 2     undercloud                     running
 -     control_0                      shut off
 -     compute_0                      shut off
 -     compute_1                      shut off
 -     compute_2                      shut off
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;logging-into-the-undercloud&#34;&gt;Logging into the undercloud&lt;/h2&gt;

&lt;p&gt;Now that our environment is up and running lets log into the undercloud so we
can start deploying our cloud.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd ~/quickstart
ssh -F ssh.config.ansible stack@undercloud
[stack@undercloud ~]$
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;initial-deployment-of-the-cloud&#34;&gt;Initial deployment of the cloud&lt;/h2&gt;

&lt;p&gt;Next we want to do an initial deployment of our environment. We&amp;rsquo;ll be
provisiong a single controller and a single compute node to start. Prior to
Newton we would normally deploy using several &lt;code&gt;--scale&lt;/code&gt; and &lt;code&gt;--flavor&lt;/code&gt; flags
since we had a limited set of roles available to us. With Newton we have a lot
more range as to what services make up a role, meaning the built in flags no
longer make a lot of sense.&lt;/p&gt;

&lt;p&gt;This OpenStack change resulted in the flags being deprecated: &lt;a href=&#34;https://review.openstack.org/#/c/378667/3/tripleoclient/utils.py&#34;&gt;OpenStack Review 378667&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Instead, we should be deploying using a template file instead. Before looking
at the template lets look at what our previous deployment command might have
looked like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source stackrc

openstack overcloud deploy \
  --control-flavor control \
  --control-scale 1 \
  --compute-flavor compute \
  - compute-scale 1 \
  --templates \
  --libvirt-type qemu \
  --timeout 90 \
  -e /usr/share/openstack-tripleo-heat-templates/environments/network-isolation.yaml \
  -e /usr/share/openstack-tripleo-heat-templates/environments/net-single-nic-with-vlans.yaml \
  -e network-environment.yaml \
  --neutron-network-type vxlan \
  --neutron-tunnel-types vxlan \
  --ntp-server pool.ntp.org
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the top of that command we have the &lt;code&gt;--control-flavor&lt;/code&gt;, &lt;code&gt;--control-scale&lt;/code&gt;,
&lt;code&gt;--compute-flavor&lt;/code&gt;, and &amp;lsquo;&amp;ndash;compute-scale&amp;rsquo; flags. Since we now have composable
roles (and that means we could really have any number of roles and flavors)
having a built in flag doesn&amp;rsquo;t make a lot of sense. Instead, we move the
scale and flavor assignments into a template file.&lt;/p&gt;

&lt;p&gt;I created a new file in the home directory called &lt;code&gt;deploy.yaml&lt;/code&gt;. The contents
are pretty straight forward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;parameter_defaults:
    OvercloudControlFlavor: control
    OvercloudComputeFlavor: compute
    ControllerCount: 1
    ComputeCount: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this template we&amp;rsquo;ll get a single controller and a single compute. If we
need to scale in the future, we just need to modify the values in that file and
re-run our deployment.&lt;/p&gt;

&lt;p&gt;With our new &lt;code&gt;deploy.yaml&lt;/code&gt; file lets adjust our &lt;code&gt;overcloud deploy&lt;/code&gt; command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openstack overcloud deploy \
  --templates \
  --libvirt-type qemu \
  --timeout 90 \
  -e deploy.yaml \
  -e /usr/share/openstack-tripleo-heat-templates/environments/network-isolation.yaml \
  -e /usr/share/openstack-tripleo-heat-templates/environments/net-single-nic-with-vlans.yaml \
  -e network-environment.yaml \
  --neutron-network-type vxlan \
  --neutron-tunnel-types vxlan \
  --ntp-server pool.ntp.org
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And our resulting VMs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ virsh list --all
 Id    Name                           State
----------------------------------------------------
 2     undercloud                     running
 12    control_0                      running
 11    compute_0                      running
 -     compute_1                      shut off
 -     compute_2                      shut off
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;scaling-the-cloud-up-and-down&#34;&gt;Scaling the cloud up and down&lt;/h2&gt;

&lt;p&gt;Scaling the cloud up and down is really pretty straight forward at this point.
Just modify the &lt;code&gt;deploy.yaml&lt;/code&gt; to the correct values (and for the appropriate
level of hardware you have access to) and re-run the &lt;code&gt;openstack overcloud 
deploy&lt;/code&gt; command again.&lt;/p&gt;

&lt;h2 id=&#34;creating-your-own-roles&#34;&gt;Creating your own roles&lt;/h2&gt;

&lt;p&gt;In order to create your own roles you&amp;rsquo;ll need to copy the
&lt;code&gt;openstack-tripleo-heat-templates&lt;/code&gt; to your home directory and modify the
&lt;code&gt;roles_data.yml&lt;/code&gt; file directly (until &lt;a href=&#34;https://bugs.launchpad.net/tripleo/+bug/1626955&#34;&gt;this bug&lt;/a&gt;
has been resolved).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp -r /usr/share/openstack-tripleo-heat-templates/ ~/tht
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When deploying your overcloud with the &lt;code&gt;openstack overcloud deploy&lt;/code&gt; command you
would append &lt;code&gt;tht/&lt;/code&gt; after &lt;code&gt;--templates&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openstack overcloud deploy --template tht/ ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;So that&amp;rsquo;s how far I&amp;rsquo;ve gotten in one afternoon of playing around with the new
composable services and roles in TripleO. Next up will be attempting to build
out my own set of roles and see how easy it is to construct new topologies and
to move services around to different systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Console Obsession</title>
      <link>http://blog.leifmadsen.com/blog/2016/09/27/a-console-obsession/</link>
      <pubDate>Tue, 27 Sep 2016 16:11:17 -0400</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2016/09/27/a-console-obsession/</guid>
      <description>

&lt;h1 id=&#34;it-s-a-console-thing&#34;&gt;It&amp;rsquo;s A Console Thing&lt;/h1&gt;

&lt;p&gt;Recently I&amp;rsquo;ve gotten into running as many of my day-to-day applications in a
Linux console. Thought I&amp;rsquo;d briefly share the applications I&amp;rsquo;ve been playing
with.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;GerTTY&lt;/strong&gt; (&lt;a href=&#34;http://gertty.readthedocs.io/en/master/):&#34;&gt;http://gertty.readthedocs.io/en/master/):&lt;/a&gt; Synchronize and follow
Gerrit-hosted projects, and perform code reviews. It&amp;rsquo;s a bit slow, but
generally works pretty well once you get over the initial sync.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More Info&lt;/em&gt;: &lt;a href=&#34;https://major.io/2016/05/11/getting-started-gertty/&#34;&gt;https://major.io/2016/05/11/getting-started-gertty/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Weechat&lt;/strong&gt; (&lt;a href=&#34;https://weechat.org/):&#34;&gt;https://weechat.org/):&lt;/a&gt; IRC client with tiling-window manager like
options. Can split the window into various buffers in either horizontal or
vertical arrangements. Deals with multiple servers, and provides many
plugins.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More Info&lt;/em&gt;: &lt;a href=&#34;http://benoliver999.com/2014/02/18/weechatconf/&#34;&gt;http://benoliver999.com/2014/02/18/weechatconf/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Profanity.IM&lt;/strong&gt; (&lt;a href=&#34;http://profanity.im/):&#34;&gt;http://profanity.im/):&lt;/a&gt; XMPP client using libstrophe and ncurses
for an IRSSI (see Weechat&amp;hellip;) like interface. I&amp;rsquo;m using this to connect to
the Slack XMPP gateway.&lt;/p&gt;

&lt;p&gt;I had to build the project myself since there is no native RPM for Fedora.
This meant I had to also compile libstrophe and get that all installed in the
right location to make it available for Profanity. Not sure why, but I could
never get Profanity to find it in &lt;code&gt;/usr/local/lib&lt;/code&gt; so I gave up and installed
libstrophe in &lt;code&gt;/usr/lib64&lt;/code&gt; and all was well.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More Info&lt;/em&gt;: &lt;a href=&#34;http://nochair.net/posts/2015/11-09-linux-messaging.html&#34;&gt;http://nochair.net/posts/2015/11-09-linux-messaging.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;NeoMutt&lt;/strong&gt; (&lt;a href=&#34;http://www.neomutt.org/):&#34;&gt;http://www.neomutt.org/):&lt;/a&gt; Email application that I got working with
my works (Red Hat) Google Apps service. So far I&amp;rsquo;m a rookie when it comes to
using Mutt, but I&amp;rsquo;ve been reading and slowly learning some of the keys. The
sidebar certainly helps. I had to map some custom stuff to move around the
sidebar comfortable, but that wasn&amp;rsquo;t a big deal.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More Info&lt;/em&gt;: &lt;a href=&#34;https://hobo.house/2016/08/08/switching-from-mutt-to-neomutt/&#34;&gt;https://hobo.house/2016/08/08/switching-from-mutt-to-neomutt/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;OfflineIMAP&lt;/strong&gt; (&lt;a href=&#34;http://www.offlineimap.org/):&#34;&gt;http://www.offlineimap.org/):&lt;/a&gt; I&amp;rsquo;m currently writing this while
waiting for all my email to sync offline (OMG there is so much&amp;hellip;), so I
don&amp;rsquo;t even have it fully integrated yet. OfflineIMAP is an application that
I&amp;rsquo;ll integrate with NeoMutt so I can have offline email.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t really travel a lot, but I&amp;rsquo;ve been told using this along with notmuch
makes searching for emails really powerful.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More Info&lt;/em&gt;: &lt;a href=&#34;http://stevelosh.com/blog/2012/10/the-homely-mutt/&#34;&gt;http://stevelosh.com/blog/2012/10/the-homely-mutt/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Notmuch&lt;/strong&gt; (&lt;a href=&#34;https://notmuchmail.org/):&#34;&gt;https://notmuchmail.org/):&lt;/a&gt; A powerful tag-based email search system.
I haven&amp;rsquo;t even set this up yet, so I have no idea what I&amp;rsquo;m doing here :)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Yes I&#39;m still alive...</title>
      <link>http://blog.leifmadsen.com/blog/2016/07/08/yes-im-still-alive.../</link>
      <pubDate>Fri, 08 Jul 2016 16:41:52 -0400</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2016/07/08/yes-im-still-alive.../</guid>
      <description>&lt;p&gt;It&amp;rsquo;s been a while since I&amp;rsquo;ve posted, and I&amp;rsquo;ll update this blog post soon. I
just needed to get my blog set back up so I could post via Hugo :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rules For The Greater Goodness; A Product Development Guide</title>
      <link>http://blog.leifmadsen.com/blog/2015/11/19/rules-for-the-greater-goodness-a-product-development-guide/</link>
      <pubDate>Thu, 19 Nov 2015 10:21:26 -0500</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2015/11/19/rules-for-the-greater-goodness-a-product-development-guide/</guid>
      <description>

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;This page documents and provides bullets about the way to approach (or avoid) building products. These are lessons we&amp;rsquo;ve learned from previous encounters and which we wish to avoid in the future. By sticking firmly to these development rules, we avoid getting bogged down in complete system rearchitectures in the future. The means to a scaled end is to approach the first customer as all your customers.&lt;/p&gt;

&lt;h1 id=&#34;rules-for-the-greater-goodness&#34;&gt;Rules For The Greater Goodness&lt;/h1&gt;

&lt;h2 id=&#34;a-product-development-guide&#34;&gt;A Product Development Guide&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Java is strictly forbidden&lt;/strong&gt; from any client or server side applications being built or interacted with. Applications utilizing Java may be used in limited usage when warranted.

&lt;ul&gt;
&lt;li&gt;For example, Confluence, our documentation system utilized Java, but no customer interactions are had via Java, and no core systems utilize Java.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rube-Goldberg mechanisms are strictly forbidden.&lt;/strong&gt; Build simpler, more elegant solutions that scale, are documented, and utilize best practices.&lt;/li&gt;
&lt;li&gt;Utilize development tools and languages that speak to the strengths of the system being built. Prefer using languages already in use. Have a primary development language.&lt;/li&gt;
&lt;li&gt;If you can interact with an &lt;strong&gt;API&lt;/strong&gt;, do it. If you need to expose data to another subsystem, front it with an API.&lt;/li&gt;
&lt;li&gt;Love documentation. Be one with documentation. &lt;strong&gt;Document&lt;/strong&gt; your code for the next fool that needs to work on it. It&amp;rsquo;s probably going to be you.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automate everything&lt;/strong&gt; you can so you can spend time building new functionality.&lt;/li&gt;
&lt;li&gt;Build in as much &lt;strong&gt;redundancy&lt;/strong&gt; and automatic &lt;strong&gt;failover&lt;/strong&gt; as possible. Capture errors in sane manners. The focus is to build systems that require very little support. Support costs money.&lt;/li&gt;
&lt;li&gt;If you have a choice between a pre-paid solution and an open source solution, but the open source solution requires more effort, it doesn&amp;rsquo;t matter. &lt;strong&gt;Use open source software.&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Avoid vendor lock&lt;/strong&gt; in at all costs. It costs!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load testing&lt;/strong&gt; is paramount, and realistic load testing even more so.  If you don&amp;rsquo;t know the loads at which your application will break you can&amp;rsquo;t know what customer experiences will be like.

&lt;ul&gt;
&lt;li&gt;If you don&amp;rsquo;t know the expected load, how do you expect to monitor it? How will you know what your thresholds are for warning and critical alarms?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monitor&lt;/strong&gt; your network and applications. Understand what they are doing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log your data.&lt;/strong&gt; Log your network traffic, your application logs, and your API interactions. Provide a simple interface for gathering data. Don&amp;rsquo;t rely on trying to reproduce issue after the fact.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Have style.&lt;/strong&gt; When possible write a style guide for what you&amp;rsquo;re building. Keeping things clean will produce better code in the future. If your code is pretty and conforms to code guidelines you&amp;rsquo;re less likely to hack and slash. Follow the style guides.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Contribute.&lt;/strong&gt; Using open-source projects is a two-way street. Any contributions we can make back to the community helps both the project and us.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normalize&lt;/strong&gt; your database tables. Database creation should strive towards fifth normal form (5NF). See &lt;a href=&#34;http://en.wikipedia.org/wiki/Fifth_normal_form&#34;&gt;Fifth Normal Form&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Control the applications.&lt;/strong&gt; Don&amp;rsquo;t deploy applications to clients that you can&amp;rsquo;t control and upgrade. Subscribing to a hosted mentality is that you have a single application for all clients. Own this and everyone will benefit from the same platform.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limit Customization.&lt;/strong&gt; If you&amp;rsquo;re going to build the functionality for a client, make sure the time you&amp;rsquo;re spending is helping the greater good. Architect and develop features requested by clients in such a way that they are generic and help the greater community (your client base).

&lt;ul&gt;
&lt;li&gt;Small customizations derail your forward momentum and take you on tangents.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sell what you have.&lt;/strong&gt; Don&amp;rsquo;t sell what the customer wants and lock yourself into having to build functionality in a rush. Sell the merits of the platform to the customer and help them understand why a customization for them hurts other customers on the platform, and that you don&amp;rsquo;t want to hurt your customers; including them. See 15 and 16.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User experience&lt;/strong&gt; is paramount. It should be well researched and designed with ease-of-use in mind. Engineers should never try to directly implement UX concepts; well-designed software should always be abstracted from design elements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set reasonable and hard limits&lt;/strong&gt; for expectations of the platform. Don&amp;rsquo;t allow the platform or any of its features to be misrepresented or misconstrued. See 17.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Constant innovation&lt;/strong&gt; is imperative to the success of the platform. No one wants old technology and all technology becomes obsolete almost immediately.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Never ignore customer feedback!&lt;/strong&gt; Even if it&amp;rsquo;s not feasible to implement a customer&amp;rsquo;s request, the request is generally always coming from an actual use-case.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examine and understand use-cases.&lt;/strong&gt; Always make sure the use-case is understood so that a proper solution can be implemented.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Asterisk Docker Container: Phase 1</title>
      <link>http://blog.leifmadsen.com/blog/2015/11/10/asterisk-docker-container-phase-1/</link>
      <pubDate>Tue, 10 Nov 2015 19:41:55 -0500</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2015/11/10/asterisk-docker-container-phase-1/</guid>
      <description>

&lt;h2 id=&#34;astricon&#34;&gt;AstriCon&lt;/h2&gt;

&lt;p&gt;At AstriCon 2015 this year, there was a lot (and I mean a lot) of discussion around microservices (Docker),
and what effort is required over the next year by the development community in order to make Asterisk better
suited to running in that environment.&lt;/p&gt;

&lt;p&gt;One of the first things is, clearly, to have a container image that Asterisk runs in. I&amp;rsquo;ve done this a
few times now, but having something that can be passed over to the official Asterisk Git repository,
and which everyone can contribute to, utilize and play with would be the goal here. The community is
already pretty fragmented, and there are a bunch of useful, but unofficial images, and I don&amp;rsquo;t think
any of them have become the defacto image.&lt;/p&gt;

&lt;h2 id=&#34;the-problem-reproducibility&#34;&gt;The Problem; Reproducibility&lt;/h2&gt;

&lt;p&gt;Part of the problem is really around packages. Digium does release some official Asterisk packages, but
it&amp;rsquo;s not automated. Another interesting tidbit that came out of AstriDevCon is that no one really uses packages.&lt;/p&gt;

&lt;p&gt;Let me elaborate on what I mean by that. Steve Sokol actually made that statement, and at first I was shocked.
As he talked a bit more, there was a bit of an a-ha moment, so let me try and distill it. Remember that we&amp;rsquo;re in
a room of developers and highly skillful integrators. When Steve said, &amp;ldquo;no one uses packages&amp;rdquo;, he was referring
to a poll that was done of developers and integrators, and asking if they deploy their systems to customers using
the defacto packages that are provided with the various distributions.&lt;/p&gt;

&lt;p&gt;The issue isn&amp;rsquo;t that we don&amp;rsquo;t have access to packages, but that the packages we do have access to don&amp;rsquo;t contain
the various bits of custom code that developers and highly skilled integrators tend to absorb and deploy. So what
ultimately happens is that code gets compiled on the system with the changes, and away everyone goes.&lt;/p&gt;

&lt;p&gt;Of course these same people are more than intelligent enough to handle their own packaging. The issue tends to be
that creating your own packages and managing them is a bit of a pain in the ass. It&amp;rsquo;s extra overhead that never
seems to ultimately bubble up to a high enough priority to solve (in many cases). No one likes shaving yaks to get
their work done.&lt;/p&gt;

&lt;p&gt;So with that sidebar out of the way, let me ask a question: how does building an &amp;ldquo;official&amp;rdquo; Docker image solve
any of that? The answer is, it doesn&amp;rsquo;t. We end up in the exact same situation, with everyone having their own
Docker images and their own Dockerfile that as borrowed from someone else, and we end up with community
fragmentation.&lt;/p&gt;

&lt;h2 id=&#34;approaching-a-solution&#34;&gt;Approaching A Solution&lt;/h2&gt;

&lt;p&gt;I think there is a solution here though. Docker makes the building of utility services significantly easier than
someone having to install applications, spin up the corresponding services, configure them, and ultimately host
them on their infrastructure. And we&amp;rsquo;re not even talking yet about people who run Ubuntu vs CentOS vs Debian vs
Mint vs&amp;hellip; Gentoo?&lt;/p&gt;

&lt;p&gt;However, the underlying distribution in a Docker-based infrastructure becomes much less of a concern. We have
these nice abstraction points called &amp;ldquo;containers&amp;rdquo; :) With the framework of a single container, the distribution
can be one type, and it can interact with other containers that are other distribution types through things like
volumes, networking, etc. We can also distribute portions of the infrastructure into nice little container images
with minimal setup time for the infrastructure owner.&lt;/p&gt;

&lt;p&gt;With one or more containers, we can easily distribute the functionality that would normally be maintained by each
person locally, and make the maintenance of that functionality a bit more centralized through the distribution of
containers for each of those purposes. Then the only real documentation should be how to use the containers to
achieve the same goals as would be done in a virtual machine installation. Ideally with significantly less investment
of time as well.&lt;/p&gt;

&lt;p&gt;The goal then here, is to create a foundation that allows the building of Asterisk and distributing it via a
container image relatively simple. We can then avoid any centralized infrastructure spin up that needs to be owned
by a single organization or individual, allowing collaboration across organizations and developers, and also allowing
everyone to have a slightly tweaked deployment without the overhead of maintaining the entire stack.&lt;/p&gt;

&lt;h2 id=&#34;a-draft-solution&#34;&gt;A Draft Solution&lt;/h2&gt;

&lt;p&gt;With that in mind, we also want people to have access to an Asterisk container image that they can use,
but with the ability to rebuild it locally if need be, without having to setup a ton of infrastructure to
do it. As a first step, it would be ideal to just have something that is reproducible.&lt;/p&gt;

&lt;p&gt;The simplest solution is really just to build Asterisk from source that is mounted via volume into the container
during build. While this definitely solves multple problems, it provides its own set of obstacles. Primarily that
it results in a large number of dependencies built into the container which results in a large container image.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: There are ways around this, but it kind of breaks the simplicity of the &lt;code&gt;Dockerfile&lt;/code&gt; when you break out
information into external scripts. Externalizing everything also breaks the readability of the container build
itself when you do a &lt;code&gt;docker inspect&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The best way of building the Asterisk container image is to use packages, since that doesn&amp;rsquo;t increase the size of
the distributed container image. It also keeps the &lt;code&gt;Dockerfile&lt;/code&gt; readable and a single layer of information. But
now we&amp;rsquo;re right back to our &amp;ldquo;building packages is hard&amp;rdquo; issue. Luckily with Docker we can make this a significantly
more appealing a process.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Since I started working on this, Alan Graham posted some links to RPM building containers which might
also be useful for this. I&amp;rsquo;m currently approaching this slightly differently, but there may be an opportunity
to circle back around and see how these images could also be used to solve the problem:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alanfranz/docker-rpm-builder&#34;&gt;https://github.com/alanfranz/docker-rpm-builder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alanfranz/fpm-within-docker&#34;&gt;https://github.com/alanfranz/fpm-within-docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;In my first approach, I didn&amp;rsquo;t want to rewrite all the SPEC file madness for Asterisk. That&amp;rsquo;s a big job. I&amp;rsquo;ve
previously built RPMs for Asterisk (many times) using the
&lt;a href=&#34;http://pkgs.fedoraproject.org/cgit/asterisk.git/&#34;&gt;asterisk.spec file&lt;/a&gt; from the Fedora project. It&amp;rsquo;s a great
starting point, and usually with some mild tweaking I can get what I want out of it. The most typical thing
I do is add my own custom changes to the &lt;code&gt;.spec&lt;/code&gt; file, change versions, maintainer, etc and then build the RPMs
with &lt;a href=&#34;https://fedoraproject.org/wiki/Mock&#34;&gt;mock&lt;/a&gt;. This is better than having a dependent VM or something for
building the RPMs, but it still requires knowledge of using &lt;code&gt;mock&lt;/code&gt; and then of course modifying the &lt;code&gt;spec&lt;/code&gt;
files in the first place. You also need to have a Fedora or CentOS machine to work on.&lt;/p&gt;

&lt;p&gt;We can simplify this with a Docker container image that builds the RPMs for us. I did that here:
&lt;a href=&#34;https://github.com/leifmadsen/asterisk-docker-builder/tree/0.1&#34;&gt;asterisk-docker-builder version 0.1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The solution I took was to reuse some of the RPM building tools supplied by the Fedora project. Using
&lt;code&gt;fedpkg&lt;/code&gt; I could generate the dependencies I required, load them into a local repo, and use that to step
through the dependency stack. With the &lt;code&gt;.spec&lt;/code&gt; files already created, there wasn&amp;rsquo;t much extra work to do since
I could install dependencies with &lt;code&gt;yum-builddep&lt;/code&gt; and then use &lt;code&gt;createrepo&lt;/code&gt; to build a local RPM repository
that could host the dependencies not available from upstream CentOS.&lt;/p&gt;

&lt;p&gt;You can see that I somewhat break my own rule and use a &lt;code&gt;buildit.sh&lt;/code&gt; script, but since this was just for the
RPM builder, I let it slide for now. The resulting RPMs are then used during the build process for the Asterisk
container image. This results in a huge savings of space; with the compiled version of the Docker image, the
size was 1.6GB, but with RPMs, it is closer to 500MB.&lt;/p&gt;

&lt;h2 id=&#34;outstanding-issues&#34;&gt;Outstanding Issues&lt;/h2&gt;

&lt;p&gt;I consider the solution I&amp;rsquo;ve been working on far from complete. In this blog post I also don&amp;rsquo;t get into
how I solved all the little things, and how to use the images (I think I did a decent version of that in
the &lt;code&gt;README.md&lt;/code&gt; file within the Github repo). Here are a few of the problems yet to be solved:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;dependency on the upstream &lt;code&gt;spec&lt;/code&gt; file from Fedora&lt;/li&gt;
&lt;li&gt;dependency on &lt;code&gt;fedpkg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;inability to build packages easily from local source&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let me break down a bit further why the above are issues.&lt;/p&gt;

&lt;h3 id=&#34;dependency-on-upstream-spec&#34;&gt;Dependency on upstream &lt;code&gt;spec&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;When we rely on the upstream &lt;code&gt;spec&lt;/code&gt; file, we&amp;rsquo;re not really a lot further ahead. Sure we have the ability to reproduce
builds pretty easily, but to a certain degree we&amp;rsquo;re stuck with whatever version is being packaged upstream. The file not
being local makes it difficult to manage, so we&amp;rsquo;re kind of back to building packages ourselves.&lt;/p&gt;

&lt;h3 id=&#34;dependency-on-fedpkg&#34;&gt;Dependency on &lt;code&gt;fedpkg&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;A dependency on &lt;code&gt;fedpkg&lt;/code&gt; is actually a nice thing to a certain degree, but doesn&amp;rsquo;t solve all our &amp;ldquo;build from local source&amp;rdquo;
problems. With &lt;code&gt;fedpkg&lt;/code&gt; the default is to grab the &lt;code&gt;spec&lt;/code&gt; file and sources from a server hosted via Fedora itself (thus we&amp;rsquo;re)
building the same RPMs that Fedora ships with their systems), but there is an override configuration file we can use. With
the override configuration file, we could actually point at our own &lt;code&gt;spec&lt;/code&gt; file hosted in &lt;code&gt;git&lt;/code&gt; and also point at our own
&lt;code&gt;sources&lt;/code&gt; location, where our own tarball of Asterisk resides (with our own changes).&lt;/p&gt;

&lt;p&gt;Of course this goes back to having to deploy our own infrastructure to support building packages. It&amp;rsquo;s not ideal, but it&amp;rsquo;s
definitely much less than normal. I think there are things we can do with companion containers though to make this much
more flexible. There might be other tools that are even better than &lt;code&gt;fedpkg&lt;/code&gt; to make the building simpler.&lt;/p&gt;

&lt;h3 id=&#34;inability-to-build-from-local-source&#34;&gt;Inability to build from local source&lt;/h3&gt;

&lt;p&gt;Right now we technically could build packages using the &lt;code&gt;fedpkg.conf&lt;/code&gt; overrides and point it at some other
infrastructure (either self-hosted, or supplied via companion containers). The primary issue is if you wanted
to build a development container for testing some code directly from your local source directory without all
the extra work of building tarballs, uploading them to a remote server, and updating a &lt;code&gt;spec&lt;/code&gt; file, you&amp;rsquo;re kind
of out of luck.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;I think at this point some additional work could be done here to make this all a little less difficult. For
example the usage of &lt;a href=&#34;https://github.com/jordansissel/fpm&#34;&gt;FPM&lt;/a&gt; within a companion container could make the
creation of the packages much simpler. If that approach succeeds then we skip a lot of the overhead of having
to maintain &lt;code&gt;spec&lt;/code&gt; files, outside infrastructure to make the files available to &lt;code&gt;fedpkg&lt;/code&gt; and a few other things
that make building packages annoying. It&amp;rsquo;s not clear yet whether FPM really works well for complex applications
like Asterisk that have multiple outside dependencies, but it&amp;rsquo;s worth a look.&lt;/p&gt;

&lt;p&gt;The other approach I&amp;rsquo;ve been thinking about is to have a &lt;code&gt;spec&lt;/code&gt; file per Asterisk version supplied directly
with Asterisk, which makes the editing of the file locally probably a lot simpler since it&amp;rsquo;ll be tied to your
base version of Asterisk. From there you simply need to add any extra modules / files that you&amp;rsquo;re adding to the
Asterisk source code. If changes only happen in existing file, then there should be no need to change the file
at all, other than maybe a build flag change (which you might be able to pass in with an &lt;code&gt;ENV&lt;/code&gt; variable).&lt;/p&gt;

&lt;p&gt;To solve the issue with building a package from the local source, we could volume mount the working directory
or Asterisk code back into the container during the &lt;code&gt;docker run&lt;/code&gt; and &lt;code&gt;tar&lt;/code&gt; the source up, place the resulting
archive into a particular directory, update the signature file, and create a new RPM. Building your own local
Asterisk container then would be relatively straight forward.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I know this has been a lengthy post, but I wanted to get all the background fleshed out so that anyone wanting
to jump into this had the prerequisite information. I have some approaches I&amp;rsquo;m going to attempt moving forward
with (likely FPM to start, since I think that creates a simple avenue if it works out), but anyone who wanted
to assist with this is more than welcome to get with me, and provide some other information.&lt;/p&gt;

&lt;p&gt;Maybe there are some simple tweaks I&amp;rsquo;m not seeing, or some other problem to be solved that I haven&amp;rsquo;t run into yet.
The goal here is to get the requisite &lt;code&gt;Dockerfile&lt;/code&gt; or files into the Asterisk repository, add some documentation
and make it simple for people to build their own Asterisk containers with their source. Of course if all you
need is a vanilla Asterisk container right now, I&amp;rsquo;m already hosting one from the resulting RPMs built by the
Fedora projects &lt;code&gt;spec&lt;/code&gt; and &lt;code&gt;fedpkg&lt;/code&gt; at the &lt;a href=&#34;https://hub.docker.com/r/leifmadsen/asterisk/&#34;&gt;Docker Hub&lt;/a&gt; under my
repository.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>about</title>
      <link>http://blog.leifmadsen.com/about/</link>
      <pubDate>Tue, 10 Nov 2015 19:28:26 -0500</pubDate>
      
      <guid>http://blog.leifmadsen.com/about/</guid>
      <description>&lt;p&gt;Leif Madsen has been an Asterisk consultant since 2004 and has been working with Asterisk since September, 2002.
He is also co-author of the O&amp;rsquo;Reilly Media published books, Asterisk: The Future of Telephony 1st and 2nd editions (along with Jared Smith and Jim van Meggelen),
Asterisk: The Definitive Guide (3rd edition) with Jim van Meggelen and Russell Bryant, and the Asterisk Cookbook with Russell Bryant.&lt;/p&gt;

&lt;p&gt;As an active member of the Asterisk community, Leif was formerly the primary issue marshal on the Asterisk issue tracker, in addition to the Asterisk release manager. Some of the projects Leif has built or implemented include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a distributed, fault-tolerant, and self-healing network for an ITSP&lt;/li&gt;
&lt;li&gt;an E911 portal for customers to update their address for their VoIP line utilizing SOAP&lt;/li&gt;
&lt;li&gt;a multi-site call centre for a job recruiting agency that allows agents to login to remote queues&lt;/li&gt;
&lt;li&gt;founder of the Asterisk Documentation Project; basis of the first edition of Asterisk: The Future of Telephony&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, Leif has spoken at many Asterisk conferences, helped write the first Asterisk training classes and dCAP (Digium Certified Asterisk Professional) test,
helped to steer the implementation of several features in Asterisk, and performed consulting for dozens of clients over the years.
You can be assured you&amp;rsquo;re getting one of the most highly qualified Asterisk consultants in the business.&lt;/p&gt;

&lt;p&gt;Leif resides in Caledon, Ontario, Canada but has worked remotely for customers all over the world.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker container results in x509: failed to load system roots and no roots provided</title>
      <link>http://blog.leifmadsen.com/blog/2015/10/30/docker-container-results-in-x509-failed-to-load-system-roots-and-no-roots-provided/</link>
      <pubDate>Fri, 30 Oct 2015 20:30:27 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2015/10/30/docker-container-results-in-x509-failed-to-load-system-roots-and-no-roots-provided/</guid>
      <description>&lt;p&gt;We have a small system running in AWS as a CentOS 7 image. It has a few containers that we&amp;rsquo;re using to host a few Golang API proxies. We migrated a customers API proxy that was running on the local VM into a container, and spun it up. Upon testing, we ran into the following error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x509: failed to load system roots and no roots provided
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We get that failure when trying to connect to an HTTPS endpoint (remote API that we&amp;rsquo;re proxying to Asterisk).&lt;/p&gt;

&lt;p&gt;Figured it had to do with the fact we were using a scratch disk to build the container image, and that there were no certs loaded. Did some Googling and found some people with similar problems, but their solutions didn&amp;rsquo;t work for us on our CentOS 7 host system.&lt;/p&gt;

&lt;p&gt;Then I thought maybe there was some issue with following a symlink as the source since we were loading in the &lt;code&gt;ca-bundle.crt&lt;/code&gt; file as a volume. I didn&amp;rsquo;t test enough to determine if that was the issue (it probably wasn&amp;rsquo;t), but this post gave me a hint:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/issues/5157#issuecomment-69325677&#34;&gt;https://github.com/docker/docker/issues/5157#issuecomment-69325677&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So we did the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d -p 8085:8085 -v /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem:/etc/ssl/certs/ca-certificates.crt [etc...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After linking that file and mounting it in the container, all was well. I suspect it&amp;rsquo;s the path to the &lt;code&gt;ca-certificates.crt&lt;/code&gt; that was the real trick.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Configuring powerline to show working Git branch</title>
      <link>http://blog.leifmadsen.com/blog/2015/09/09/configuring-powerline-to-show-working-git-branch/</link>
      <pubDate>Wed, 09 Sep 2015 21:20:40 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2015/09/09/configuring-powerline-to-show-working-git-branch/</guid>
      <description>&lt;p&gt;So the documentation for &lt;a href=&#34;http://powerline.readthedocs.org/en/latest/index.html&#34;&gt;Powerline&lt;/a&gt;Â kind of sucks. I followed &lt;a href=&#34;http://fedoramagazine.org/add-power-terminal-powerline&#34;&gt;this&lt;/a&gt; pretty good article on getting started with it. First thing I noticed however is that the &lt;code&gt;if&lt;/code&gt; statement on the article doesn&amp;rsquo;t work if you don&amp;rsquo;t have powerline installed (which kind of defeats the purpose of having the &lt;code&gt;if&lt;/code&gt; statement there at all).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if powerline is installed, then use it
command -v powerline-daemon &amp;amp;&amp;gt;/dev/null
if [ $? -eq 0 ]; then
powerline-daemon -q
POWERLINE_BASH_CONTINUATION=1
POWERLINE_BASH_SELECT=1
. /usr/share/powerline/bash/powerline.sh
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next up is the configuration. I primarily use my bash prompt as a way to indicate which branch I&amp;rsquo;m working in within a Git repository. You need to point at the &lt;code&gt;default_leftonly&lt;/code&gt; theme which is pretty easy to find when you web search for it. The issue is everything seems to just point you at the powerline docs, which aren&amp;rsquo;t the most clear.&lt;/p&gt;

&lt;p&gt;First, start by creating a local configuration directory that will override the configuration for powerline for your user.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mkdir -p ~/.config/powerline
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the next thing is to copy over the &lt;code&gt;config.json&lt;/code&gt; from the main powerline configuration directory where you can find the available color schemes and other shell, i3, vim, etc themes.&lt;/p&gt;

&lt;p&gt;(Again, the documentation kind of sucks on where the root of these configurations live&amp;hellip;)&lt;/p&gt;

&lt;p&gt;On my Fedora 22 system they live in &lt;code&gt;/etc/xdg/powerline/&lt;/code&gt;. I then copy the &lt;code&gt;config.json&lt;/code&gt; from that directory to &lt;code&gt;~/.config/powerline&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To get the Git branch stuff going, I modified the configuration file in the following way:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;--- /etc/xdg/powerline/config.json 2015-02-18 18:56:51.000000000 -0500
+++ /home/lmadsen/.config/powerline/config.json 2015-09-09 17:11:43.937522571 -0400
@@ -18,7 +18,7 @@
},
&amp;quot;shell&amp;quot;: {
&amp;quot;colorscheme&amp;quot;: &amp;quot;default&amp;quot;,
- &amp;quot;theme&amp;quot;: &amp;quot;default&amp;quot;,
+ &amp;quot;theme&amp;quot;: &amp;quot;default_leftonly&amp;quot;,
&amp;quot;local_themes&amp;quot;: {
&amp;quot;continuation&amp;quot;: &amp;quot;continuation&amp;quot;,
&amp;quot;select&amp;quot;: &amp;quot;select&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make it active you can run &lt;code&gt;powerline-config --reload&lt;/code&gt;. If you have any errors in your configuration (I actually ran into this when playing with the colorscheme setting and used &amp;ldquo;solorized&amp;rdquo; instead of &amp;ldquo;solarized&amp;rdquo;), you can check it with &lt;code&gt;powerline-lint&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rumors of my death have been greatly exaggerated</title>
      <link>http://blog.leifmadsen.com/blog/2014/07/25/rumors-of-my-death-have-been-greatly-exaggerated/</link>
      <pubDate>Fri, 25 Jul 2014 02:49:12 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2014/07/25/rumors-of-my-death-have-been-greatly-exaggerated/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s been way too long since I&amp;rsquo;ve blogged. And this post isn&amp;rsquo;t going to be all the impressive unfortunately. However, I recently have been running a BBS and some friends and I have been playing LORD.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve been playing this for the last few months, and I think I&amp;rsquo;m going to run a tournament. Perhaps with some sort of buy in like $10 or something, winner takes all.&lt;/p&gt;

&lt;p&gt;Going to build it out in such a way that first person to beat the dragon 3 times will win the game, and at that point that person will win the pot.&lt;/p&gt;

&lt;p&gt;Additionally, I&amp;rsquo;ve been reading a lot about the Go language and trying to get myself up to speed on that. Very interesting programming language. Essentially C but for concurrency (multiple processors).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m hoping to start blogging in the near future, but my current work has just kept me too busy and I haven&amp;rsquo;t really had anything all that worth of blogging about. I hope to start changing that around soon and get back to blogging on a semi-regular basis with things I&amp;rsquo;ve learned in the world of telecommunications and cloud platforms / virtualization.&lt;/p&gt;

&lt;p&gt;Additionally, I don&amp;rsquo;t have any confirmation yet, but I&amp;rsquo;m pretty sure I&amp;rsquo;ll be attending AstriCon in Las Vegas this year. I&amp;rsquo;m going to figure it out either way, so hopefully i can meet up with some of you this year! The last few years I&amp;rsquo;ve just kind of mostly kept to myself and hung out with those I&amp;rsquo;ve met previously. I&amp;rsquo;m going to make a better attempt at reaching out to those I haven&amp;rsquo;t met before, so if you see me, come say hi please!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Asterisk: The Definitive Guide 4th Edition goes to print</title>
      <link>http://blog.leifmadsen.com/blog/2013/05/16/asterisk-the-definitive-guide-4th-edition-goes-to-print/</link>
      <pubDate>Thu, 16 May 2013 13:31:46 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2013/05/16/asterisk-the-definitive-guide-4th-edition-goes-to-print/</guid>
      <description>&lt;p&gt;Howdy folks,&lt;/p&gt;

&lt;p&gt;Sorry for the lack of updates lately. I&amp;rsquo;ve recently (December 2012) started at Thinking Phone Networks as the Lead UC Systems Engineer, and we&amp;rsquo;ve been incredibly busy there. In addition, the authors and I had been working on the final touches to the 4th edition of Asterisk: The Definitive Guide, which documents Asterisk 11 LTS.&lt;/p&gt;

&lt;p&gt;Late last week, the book went to print, and should start to appear on store shelves and start shipping from Amazon and other locations within the next 6-8 weeks I believe. However, if you&amp;rsquo;ve purchased the digital version, it&amp;rsquo;s already available!&lt;/p&gt;

&lt;p&gt;I got mine from O&amp;rsquo;Reilly, and sync&amp;rsquo;d it to my Dropbox and shared it with my co-workers. There are usually deals around on Amazon and the O&amp;rsquo;Reilly website that will let you purchase both the digital and printed versions. The digital should be available immediately, with the printed version shipping as soon as it&amp;rsquo;s available.&lt;/p&gt;

&lt;p&gt;Thanks to everyone who helped make the 4th edition a success, and to get it done in the last 8 months! It&amp;rsquo;s been quite the journey since the 1st edition was released in 2005.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brother printer doesn&#39;t print in Fedora 17</title>
      <link>http://blog.leifmadsen.com/blog/2012/11/24/brother-printer-doesnt-print-in-fedora-17/</link>
      <pubDate>Sat, 24 Nov 2012 22:06:03 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2012/11/24/brother-printer-doesnt-print-in-fedora-17/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Tip: If your Brother printer won&amp;rsquo;t print after installing the drivers, install glibc.i686&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Today ran into an issue with my new Brother MFC-7460DN (which is a really nice laser printer with auto-feed scanner, Scan-to-FTP which creates a PDF file, and other things). I had just recently done a clean install of Fedora 17, and I could install the RPMs (which are i386 files on my x86_64 based system), add the printer to CUPS and all sorts of things that looked fine.&lt;/p&gt;

&lt;p&gt;However when I went to print, it wouldn&amp;rsquo;t error out, but the printer wouldn&amp;rsquo;t actually print. I tried changing a file perÂ &lt;a href=&#34;https://bbs.archlinux.org/viewtopic.php?pid=940524#p940524&#34;&gt;https://bbs.archlinux.org/viewtopic.php?pid=940524#p940524&lt;/a&gt;Â but it didn&amp;rsquo;t help.&lt;/p&gt;

&lt;p&gt;Then I found this postÂ &lt;a href=&#34;http://forums.fedoraforum.org/showthread.php?t=280753&#34;&gt;http://forums.fedoraforum.org/showthread.php?t=280753&lt;/a&gt;Â which reminded me to install glibc.i686. Wish the Brother drives would just make that a dependency in the RPM.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Digium D40 and D70 Phone Unboxing</title>
      <link>http://blog.leifmadsen.com/blog/2012/10/11/digium-d40-and-d70-phone-unboxing/</link>
      <pubDate>Thu, 11 Oct 2012 20:43:35 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2012/10/11/digium-d40-and-d70-phone-unboxing/</guid>
      <description>

&lt;p&gt;Today I received a couple of &lt;a href=&#34;http://www1.digium.com/en/products/phones&#34;&gt;phones&lt;/a&gt; from Digium; the D40 and D70. I&amp;rsquo;ll be using these phones for testing and documentation in the 4th edition of &lt;a href=&#34;http://shop.oreilly.com/product/9780596517342.do&#34;&gt;Asterisk: The Definitive Guide&lt;/a&gt; (which &lt;a href=&#34;http://www.coretel.ca/&#34;&gt;Jim Van Meggelen&lt;/a&gt;, &lt;a href=&#34;http://russellbryant.net&#34;&gt;Russell Bryant&lt;/a&gt; and &lt;a href=&#34;http://leifmadsen.com&#34;&gt;myself&lt;/a&gt; are working on right now).&lt;/p&gt;

&lt;p&gt;Here is my unboxing of the phones and some commentary about my initial impressions of the hardware itself.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_484&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-01.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-01.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Pretty boxes![/caption]&lt;/p&gt;

&lt;p&gt;Phones arrived in some nice looking boxes.&lt;/p&gt;

&lt;h2 id=&#34;digium-d40&#34;&gt;Digium D40&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-33.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-33.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-59.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-42-59.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comes with a little pamphlet to help you get the phones setup on your network.&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-43-17.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-43-17.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-43-55.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-43-55.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-45-16.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-45-16.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comes with all the little things you need to get the phone up and running, including a network cable. I was just using POE to power the phone, so I didn&amp;rsquo;t end up with the 5VDC power adapter.
&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-47-01.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-47-01.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nice looking base. Easy to put onto the phone. Just uses friction to hold the phones on the base. Not sure how well that&amp;rsquo;ll work over time, but this isn&amp;rsquo;t something that should be getting attached and detached a lot. The space for cables in the base is also quite large.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_491&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-48-58.jpg?w=300&#34; alt=&#34;&#34; /&gt; Holes to mount to wall. Requires adapter.[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_492&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-49-36.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-49-36.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Easy access![/caption]&lt;/p&gt;

&lt;p&gt;Lots of space for my hand to plug in cables. Much nicer than any of the Polycom bases where I usually give up and just remove it.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_495&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-51-00.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-51-00.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Boot screen[/caption]&lt;/p&gt;

&lt;p&gt;Booting up with the Digium logo.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-49-56.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-49-56.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-50-51.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-50-51.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_496&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-54-35.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-54-35.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Handset hook access[/caption]&lt;/p&gt;

&lt;p&gt;The tab on the back here is well designed so that you don&amp;rsquo;t require a tool to pull out and flip around. I prefer to have the hook for the handset so it doesn&amp;rsquo;t fall off the base easily. On the Polycoms (which have the same type of setup) it&amp;rsquo;s nearly impossible to remove with your fingers&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_497&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-56-01.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-56-01.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; D40 vs IP335 size comparison[/caption]&lt;/p&gt;

&lt;p&gt;.Size comparison between the D40 and IP335.&lt;/p&gt;

&lt;h2 id=&#34;digium-d70&#34;&gt;Digium D70&lt;/h2&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_498&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-57-40.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-57-40.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Open box[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_500&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-58-28.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-58-28.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Hidden compartment[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_503&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-00-52.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-00-52.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; Back of the D70[/caption]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-57-57.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-57-57.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-58-46.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-58-46.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-59-58.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-14-59-58.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-01-37.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-01-37.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-03-21.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-03-21.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t quite get the base with the wall mount holes, but impossible mounting angles on the base. Must have something to do with the manufacturing process and not having separate molds for footing.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update: Michael pointed out that the A-frame is actually two separate pieces, so with a (separately purchased) piece, you can attach it to the base and make the system wall mountable. With the number of phones I&amp;rsquo;ve actually wall mounted in deployments (I think the number is only one or two), I think I prefer the 2 options for steep and shallow angles. Neat idea.&lt;/em&gt;
&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-03-34.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-03-34.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
Side cut outs for cables that I didn&amp;rsquo;t even notice the first time through. Michael pointed out they are for cable management. Nice!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-05-20.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-05-20.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;Oh my! So much space! Very roomy :)
&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-07-22.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-07-22.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;Side by side comparison of the D70 vs the IP650 w/ sidecar.
&lt;a href=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-08-05.jpg&#34;&gt;&lt;img src=&#34;http://leifmadsen.files.wordpress.com/2012/10/2012-10-11-15-08-05.jpg?w=300&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;Front to back comparison of the D70 vs IP650 w/ sidecar.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Selecting Chef Servers With Environment Variables</title>
      <link>http://blog.leifmadsen.com/blog/2012/08/22/selecting-chef-servers-with-environment-variables/</link>
      <pubDate>Wed, 22 Aug 2012 18:49:43 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2012/08/22/selecting-chef-servers-with-environment-variables/</guid>
      <description>&lt;p&gt;Today I got playing around with dynamically selecting different chef servers in preparation for migrating some of &lt;a href=&#34;http://coredial.com&#34;&gt;our&lt;/a&gt; nodes away from our chef-dev server to our chef-live server (which I&amp;rsquo;m currently in the process of building and populating with data). I had been talking in the #chef IRC channel a few weeks back about making things dynamic, or at least easily switchable, when using multiple chef servers for different groups of servers in an environment.&lt;/p&gt;

&lt;p&gt;What I want to do, is be able to set an environment variable at my console in order to switch between chef servers. Previously I had been doing this with different files in my ~/.chef/ directory and changing symlinks between the files. This method works, but is kind of annoying. So with the help of some of the folks in #chef, and with &lt;a href=&#34;https://gist.github.com/3176332&#34;&gt;this gist&lt;/a&gt; of a sample file that someone is using for their hosted chef environment, I was able to build my own knife.rb and commit it to our chef.git repository.&lt;/p&gt;

&lt;p&gt;In our &lt;strong&gt;chef.git&lt;/strong&gt; repository, I created a directory &lt;strong&gt;.chef&lt;/strong&gt; and placed a &lt;strong&gt;knife.rb&lt;/strong&gt; file in it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd ~/src/chef-repo
$ mkdir .chef
$ touch .chef/knife.rb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I then filled &lt;strong&gt;knife.rb&lt;/strong&gt; with the following contents:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;current_dir = File.dirname(__FILE__)

sys_user = ENV[&amp;quot;USER&amp;quot;]

log_level                :info
log_location             STDOUT
node_name                sys_user
client_key               &amp;quot;#{ENV[&amp;quot;HOME&amp;quot;]}/.chef/#{ENV[&amp;quot;KNIFE_ENV&amp;quot;]}/#{ENV[&amp;quot;USER&amp;quot;]}.pem&amp;quot;
validation_client_name   &amp;quot;chef-validator&amp;quot;
validation_key           &amp;quot;#{ENV[&amp;quot;HOME&amp;quot;]}/.chef/#{ENV[&amp;quot;KNIFE_ENV&amp;quot;]}/validator.pem&amp;quot;
chef_server_url          &amp;quot;http://chef-#{ENV[&amp;quot;KNIFE_ENV&amp;quot;]}.shifteight.org:4000&amp;quot;
cache_type               &#39;BasicFile&#39;
cache_options( :path =&amp;gt; &amp;quot;#{ENV[&#39;HOME&#39;]}/.chef/checksums&amp;quot; )
cookbook_path            [ &amp;quot;#{current_dir}/../cookbooks&amp;quot;, &amp;quot;#{current_dir}/../site-cookbooks&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main key is the KNIFE_ENV environment variable which I set using: &lt;code&gt;export KNIFE_ENV=dev&lt;/code&gt; or &lt;code&gt;export KNIFE_ENV=live&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After setting the environment variable, which server I&amp;rsquo;m using is selected for me. Additionally, I copied my validation.pem and client.pem files into corresponding directories in my ~/.chef/ directory: &lt;code&gt;$ mkdir ~/.chef/{live,dev}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;With all that done, I can now easily switch between our different servers in order to start the migration of our nodes. (I might create another blog post about that in the future if I get a chance.)&lt;/p&gt;

&lt;p&gt;&amp;ldquo;BUT HOW DO I KNOW WHICH ENVIRONMENT I&amp;rsquo;M WORKING WITH?!?!?!&amp;rdquo;, you say? Oh fancy this little PS1 and function I added to my ~/.bashrc file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ &amp;quot;$KNIFE_ENV&amp;quot; == &amp;quot;&amp;quot; ]; then
 export KNIFE_ENV=&amp;quot;dev&amp;quot;
fi

function which_env {
  if [ &amp;quot;$KNIFE_ENV&amp;quot; == &amp;quot;live&amp;quot; ]; then
    echo &amp;quot;31&amp;quot;
  else
    echo &amp;quot;32&amp;quot;
  fi
}

export PS1=&#39;[\u@\h \[\033[0;36m\]\W$(__git_ps1 &amp;quot;\[\033[0m\]\[\033[0;33m\](%s) \[\033[0;`which_env`m\]~$KNIFE_ENV~&amp;quot;)\[\033[0m\]]\$ &#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Is nice :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CentOS 5.8 On AWS EC2 With Xen Kernel (PVGRUB)</title>
      <link>http://blog.leifmadsen.com/blog/2012/08/22/centos-5.8-on-aws-ec2-with-xen-kernel-pvgrub/</link>
      <pubDate>Wed, 22 Aug 2012 14:10:46 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2012/08/22/centos-5.8-on-aws-ec2-with-xen-kernel-pvgrub/</guid>
      <description>&lt;p&gt;At &lt;a href=&#34;http://coredial.com&#34;&gt;CoreDial&lt;/a&gt; we&amp;rsquo;ve been using a lot of AWS EC2 lately for building sandbox infrastructure for testing. Part of the infrastructure is a voice platform utilizing Asterisk 1.4 and 1.8, and those voice platforms are using Zaptel and DAHDI respectively for use with MeetMe(). This hasn&amp;rsquo;t been an issue previously as our testing has either been on bare metal, or in other virtual machine systems where installation of a base image and standard kernel are not an issue.&lt;/p&gt;

&lt;p&gt;However, with the introduction of a lot of EC2 instances in our testing process, we ran into issues with building our own DAHDI RPMs since there aren&amp;rsquo;t any EC2 kernel development packages outside of OpenSuSE (which we don&amp;rsquo;t use). After spending a day of trying to hack around it, Kevin found a &lt;a href=&#34;http://ec2-downloads.s3.amazonaws.com/user_specified_kernels.pdf&#34;&gt;PDF&lt;/a&gt; from Amazon that states AWS now supports the ability to load your own kernels via PVGRUB. Great! If I can do that, then I can just continue using the same RPMs I&amp;rsquo;d be building anyways (albeit the xen based kernel, but that&amp;rsquo;s easy to do in the spec file).&lt;/p&gt;

&lt;p&gt;Unfortunately this was not nearly as trivial and simple as it appeared at first. The first problem was that I had to figure out the correct magic kernel AKI that needed to be loaded, and the PDF wasn&amp;rsquo;t incredibly clear about which one to use. (There is two different styles of the AKI, one called &amp;ldquo;hd0&amp;rdquo; and another called &amp;ldquo;hd00&amp;rdquo; which I&amp;rsquo;ll get into shortly.) After searching Google and looking through several forum posts and other blogs (linked at the end), I finally found a combination that seems to work for our imported CentOS 5.8 base image. Below is a list of the steps I executed after loading up an image from our base AMI:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yum install grub kernel-xen kernel-xen-devel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grub-install /dev/sda&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd /boot/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkinitrd -f -v --allow-missing --builtin uhci-hcd --builtin ohci-hcd --builtin ehci-hcd --preload xennet --preload xenblk --preload dm-mod --preload linear --force-lvm-probe /boot/initrd-2.6.18-308.13.1.el5xen.img 2.6.18-308.13.1.el5xen&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;touch /boot/grub/menu.lst&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cat /boot/grub/menu.lst&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;default 0
timeout 1

title EC2
     root (hd0)
     kernel /boot/vmlinuz-2.6.18-308.11.1.el5xen root=/dev/sda1
     initrd /boot/initrd-2.6.18-308.11.1.el5xen.img
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the changes were made to the image, I took a snapshot of the running instances volume. I then created an image from the snapshot. When creating the image, I selected a new kernel ID. The kernel ID&amp;rsquo;s for the various zones and architectures are listed in the &lt;a href=&#34;http://ec2-downloads.s3.amazonaws.com/user_specified_kernels.pdf&#34;&gt;PDF&lt;/a&gt;. As our base image was CentOS 5.8 i386 in the us-east-1 zone, I had to select between either akiâ4c7d9525 or akiâ407d9529. The paragraph above seems to indicate there is a difference based on what type of machine you&amp;rsquo;re using, and references S3 or EBS based images. We are using EBS based images, so I tried the first one, which in the end failed miserably. After reading through the &lt;a href=&#34;http://www.ioncannon.net/system-administration/1205/installing-cent-os-5-5-on-ec2-with-the-cent-os-5-5-kernel/&#34;&gt;IonCannon&lt;/a&gt; blog post it became clear that the &lt;em&gt;hd0&lt;/em&gt; and &lt;em&gt;hd00&lt;/em&gt; AKIs are really differences in whether you have a single partition, or multiple partitions with a separate /boot/ partition.&lt;/p&gt;

&lt;p&gt;With that bit of knowledge, and knowing that we only had a single partition that contained our /boot/ directory, I knew to use &lt;strong&gt;aki-407d9529&lt;/strong&gt; (hd0). Another forum post also pointed out that I needed to enable some modules for the xen kernel or the system wouldn&amp;rsquo;t boot (and I verified that by stepping through each of the steps listed above to make sure it was required). With those two major items checked off, I am now able to build an AMI that will load with a stock CentOS Xen kernel image, making it trivial to build RPMs against now.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:
If you do happen to use separate partitions, make sure you use the &lt;strong&gt;hd00&lt;/strong&gt; AKI. In the &lt;strong&gt;menu.lst&lt;/strong&gt; you need to make sure to use &lt;em&gt;root (hd0,0)&lt;/em&gt; instead of just (hd0). Additionally, your &lt;em&gt;menu.lst&lt;/em&gt; file needs to live at &lt;em&gt;/boot/boot/grub/menu.lst&lt;/em&gt; since AWS is going to look in the &lt;em&gt;/boot/grub/menu.lst&lt;/em&gt; location on the &lt;em&gt;/boot/&lt;/em&gt; partition. On a single partition the file can just live at &lt;em&gt;/boot/grub/menu.lst&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;
* &lt;a href=&#34;https://forums.aws.amazon.com/message.jspa?messageID=202366&#34;&gt;https://forums.aws.amazon.com/message.jspa?messageID=202366&lt;/a&gt; &amp;lt;&amp;ndash; provided the mkinitfs command required to get everything to work on boot
* &lt;a href=&#34;https://forums.aws.amazon.com/message.jspa?messageID=253943&#34;&gt;https://forums.aws.amazon.com/message.jspa?messageID=253943&lt;/a&gt;
* &lt;a href=&#34;http://technotes.twosmallcoins.com/?tag=bootgrubmenulst&#34;&gt;http://technotes.twosmallcoins.com/?tag=bootgrubmenulst&lt;/a&gt;
* &lt;a href=&#34;http://www.ioncannon.net/system-administration/1205/installing-cent-os-5-5-on-ec2-with-the-cent-os-5-5-kernel/&#34;&gt;http://www.ioncannon.net/system-administration/1205/installing-cent-os-5-5-on-ec2-with-the-cent-os-5-5-kernel/&lt;/a&gt; &amp;lt;&amp;ndash; this was the best link, but was also the most verbose and overly complicated for what I needed, but it had a couple of tips in there that ended up helping a lot. The explanation of the difference between the hd0 and hd00 AKIs was they key to my success.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Assign unique hostname to dhcp client with dnsmasq</title>
      <link>http://blog.leifmadsen.com/blog/2012/07/23/assign-unique-hostname-to-dhcp-client-with-dnsmasq/</link>
      <pubDate>Mon, 23 Jul 2012 19:14:45 +0000</pubDate>
      
      <guid>http://blog.leifmadsen.com/blog/2012/07/23/assign-unique-hostname-to-dhcp-client-with-dnsmasq/</guid>
      <description>&lt;p&gt;Today I&amp;rsquo;ve been getting our lab environment setup with vagrant to auto-provision our lab servers with chef server in order to allow the development team to quickly and easily turn up and tear down web application servers.&lt;/p&gt;

&lt;p&gt;Because when the server gets spun up with vagrant, it registers itself as a new node to the chef server using its hostname. Since using localhost for every node pretty much makes the chef server useless for more than 1 virtual machine at a time, I needed to figure out how to get dnsmasq to assign a unique hostname based on the IP address being provided by dnsmasq to the dhcp client.&lt;/p&gt;

&lt;p&gt;I had seen a similar thing done with Amazon EC2 instances that when they turn up, they gets a hostname that looks similar to the private IP address it has been assigned. For example, if the private IP address assigned to the server was 192.168.12.14 it would get a hostname like &lt;em&gt;ip-192-168-12-14&lt;/em&gt;. I wanted to do a similar thing with our server.&lt;/p&gt;

&lt;p&gt;After a little bit of Googling and reading the dnsmasq configuration file, it donned on me how simple this really was. You simply need to define the hostnames that the dnsmasq server could assign to a server, list those in the &lt;em&gt;/etc/hosts&lt;/em&gt; file on the dnsmasq server, and then define the hostname you wanted to provide to the server. I didn&amp;rsquo;t want to use the MAC address of the servers (a la &lt;em&gt;dhcp-host&lt;/em&gt; option) since the MAC address will be dynamic each time I spin up a virtual machine.&lt;/p&gt;

&lt;p&gt;So in my &lt;em&gt;dnsmasq.conf&lt;/em&gt; file I might have something defined like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dhcp-range=90.100.1.120,90.100.1.124,24h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So in my &lt;em&gt;/etc/hosts&lt;/em&gt; file I&amp;rsquo;d just place the following to assign those unique hostnames:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;90.100.1.120    ip-90-100-1-120
90.100.1.121    ip-90-100-1-121
90.100.1.122    ip-90-100-1-122
90.100.1.123    ip-90-100-1-123
90.100.1.124    ip-90-100-1-124
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>